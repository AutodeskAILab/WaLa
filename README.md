# WAVELET LATENT DIFFUSION (WALA) Optimization
[![arXiv](https://img.shields.io/badge/arXiv-2401.11067-b31b1b.svg)](https://arxiv.org/pdf/2411.08017)

## Overview

Welcome to the Optimized WaLa Repository!  
This repository provides an enhanced version of WaLa for fast and efficient 3D generative modeling, supporting ONNX export and TensorRT acceleration.

## Features

- **ONNX Exporter:** Export WaLa models for cross-platform inference using a command-line interface.
- **TensorRT Conversion:** Accelerate inference on NVIDIA hardware via an easy-to-use conversion script.
- **Inference Runner:** Run optimized TensorRT inference with full argparse support.
- **Multi-Modality Support:** Operates with several modalities including single-view, multiview, pointcloud, and voxels.

## Performance

Significant speedups are achieved with ONNX and TensorRT optimizations:

| Model Variant           | Latency (s) | Throughput (items/s) |
|-------------------------|-------------|----------------------|
| WaLa                    | 5.52        | 0.18                 |
| WaLa + Fast Write       | 4.17        | 0.24                 |
| WaLa + ONNX + TensorRT  | 0.75        | 1.33                 |

*Benchmarks are provided for multiple modalities, including single-view and sketch-to-3D inference.*

## Quality Comparison

Model accuracy remains high after optimization:

| Model                | Metric | Result  |
|----------------------|--------|---------|
| WaLa                 | IoU    | 0.608   |
| WaLa + TensorRT      | IoU    | 0.5981  |
| WaLa                 | LfD    | 2435    |
| WaLa + TensorRT      | LfD    | 2466    |

## Visual Quality Comparison

Below are visual comparisons of 3D objects generated by the original WaLa model and the TensorRT-optimized version.  
For each object, the left image is the input, the middle is the original WaLa output, and the right is the TensorRT output.

| Modality    | Input Image | Original (WaLa) | Optimized (WaLa + TensorRT) | Inference Time (s: Original / TRT) |
|-------------|-------------|-----------------|-----------------------------|------------------------------------|
| Single-view | <img src="examples/single_view/apple.jpeg" style="width:200px; height:200px;" alt="apple input"/> | <img src="figures/apple.gif" style="width:200px; height:200px;" alt="apple original"/> | <img src="figures/apple_trt.gif" style="width:200px; height:200px;" alt="apple TRT"/> | 5.52 / 0.75 |
| Multiview   | <img src="figures/airplane.png" style="width:200px; height:200px;" alt="airplane input"/> | <img src="figures/plane.gif" style="width:200px; height:200px;" alt="airplane original"/> | <img src="figures/plane_trt.gif" style="width:200px; height:200px;" alt="airplane TRT"/> | 6.50 / 1.1 |
| Pointcloud  | <img src="figures/ring.png" style="width:200px; height:200px;" alt="ring input"/> | <img src="figures/ring.gif" style="width:200px; height:200px;" alt="ring original"/> | <img src="figures/ring_trt.gif" style="width:200px; height:200px;" alt="ring TRT"/> | 9.3 / 1.2 |
| Voxels      | <img src="figures/horse.png" style="width:200px; height:200px;" alt="horse input"/> | <img src="figures/horse.gif" style="width:200px; height:200px;" alt="horse original"/> | <img src="figures/horse_trt.gif" style="width:200px; height:200px;" alt="horse TRT"/> | 9.5 / 0.6 |
## Installation

- Python >= 3.10
- CUDA (if available)
- PyTorch ([installation guide](https://pytorch.org/get-started/locally/))
- Other dependencies:  
  ```sh
  pip install -r requirements.txt
  ```

## Usage

### ONNX Export

Export the model to ONNX format for the desired modality using the command-line. For example, to export the pointcloud modality:

```sh
python Optim/ONNX_Export.py --modality pointcloud
```

Other modality examples:
```sh
python Optim/ONNX_Export.py --modality voxels
python Optim/ONNX_Export.py --modality sv
python Optim/ONNX_Export.py --modality sketch
python Optim/ONNX_Export.py --modality mv
```

### TensorRT Engine Conversion

Convert the exported ONNX model to a TensorRT engine. For example, to convert the pointcloud model:

```sh
python Optim/TRT_Conversion.py --onnx_path model_pointcloud.onnx --engine_path model_pointcloud.trt
```

Other examples:
```sh
python Optim/TRT_Conversion.py --onnx_path model_voxels.onnx --engine_path model_voxels.trt
python Optim/TRT_Conversion.py --onnx_path model_sv.onnx --engine_path model_sv.trt
python Optim/TRT_Conversion.py --onnx_path model_sketch.onnx --engine_path model_sketch.trt
python Optim/TRT_Conversion.py --onnx_path model_mv.onnx --engine_path model_mv.trt
```

### Running Inference with TensorRT

Run optimized inference using the TensorRT engine with argparse configuration. For example, to run inference on pointcloud data:

```sh
python Optim/TRT_Run.py --input_dir input_pointclouds --save_dir output_objs --engine_path model_pointcloud.trt --modality pointcloud
```

Additional examples:
```sh
# Single-view / Sketch
python Optim/TRT_Run.py --input_dir input_images --save_dir output_objs --engine_path model_singleview.trt --modality singleview

# Multiview
python Optim/TRT_Run.py --input_dir input_multiview --save_dir output_objs --engine_path model_multiview.trt --modality multiview

# Voxels
python Optim/TRT_Run.py --input_dir input_voxels --save_dir output_objs --engine_path model_voxels.trt --modality voxels
```

## Citation

```bibtex
@misc{sanghi2024waveletlatentdiffusionwala,
  title={Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings},
  author={Aditya Sanghi et al.},
  year={2024},
  eprint={2411.08017},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2411.08017}
}
```

## License

This project is licensed under the MIT License.