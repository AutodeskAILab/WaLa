# WAVELET LATENT DIFFUSION (WALA) Optimization
[![arXiv](https://img.shields.io/badge/arXiv-2401.11067-b31b1b.svg)](https://arxiv.org/pdf/2411.08017)

## Overview

Welcome to the Optimized WaLa Repository!  
This repository provides an enhanced version of WaLa for fast and efficient 3D generative modeling, supporting ONNX export and TensorRT acceleration.

## Features

- **ONNX Exporter:** Export WaLa models for cross-platform inference using a command-line interface.
- **TensorRT Conversion:** Accelerate inference on NVIDIA hardware via an easy-to-use conversion script.
- **Inference Runner:** Run optimized TensorRT inference with full argparse support.
- **Multi-Modality Support:** Operates with several modalities including single-view, multiview, pointcloud, and voxels.

## Performance

Significant speedups are achieved with ONNX and TensorRT optimizations:

| Model Variant           | Latency (s) | Throughput (items/s) |
|-------------------------|-------------|----------------------|
| WaLa                    | 5.52        | 0.18                 |
| WaLa + Fast Write       | 4.17        | 0.24                 |
| WaLa + ONNX + TensorRT  | 0.75        | 1.33                 |

*Benchmarks are provided for multiple modalities, including single-view and sketch-to-3D inference.*

## Quality Comparison

Model accuracy remains high after optimization:

| Model                | Metric | Result  |
|----------------------|--------|---------|
| WaLa                 | IoU    | 0.608   |
| WaLa + TensorRT      | IoU    | 0.5981  |
| WaLa                 | LfD    | 2435    |
| WaLa + TensorRT      | LfD    | 2466    |

## Visual Quality Comparison

Below are visual comparisons of 3D objects generated by the original WaLa model and the TensorRT-optimized version.  
For each object, the left image is the input, the middle is the original WaLa output, and the right is the TensorRT output.

<table style="table-layout: fixed; width: 100%;">
  <colgroup>
    <col style="width: 120px;">  <!-- Modality -->
    <col style="width: 150px;">  <!-- Input Image -->
    <col style="width: 150px;">  <!-- Original (WaLa) -->
    <col style="width: 100px;">  <!-- Original Time -->
    <col style="width: 150px;">  <!-- Optimized (WaLa + TRT) -->
    <col style="width: 100px;">  <!-- TRT Time -->
  </colgroup>
  <thead>
    <tr>
      <th style="width: 120px;">Modality</th>
      <th style="width: 150px;">Input Image</th>
      <th style="width: 150px;">Original (WaLa)</th>
      <th style="width: 100px;">Original Time (s)</th>
      <th style="width: 150px;">Optimized (WaLa + TRT)</th>
      <th style="width: 100px;">TRT Time (s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="width: 120px;">Single-view</td>
      <td style="width: 150px;"><img src="examples/single_view/apple.jpeg" style="width:150px; height:150px; object-fit: cover;" alt="apple input"/></td>
      <td style="width: 150px;"><img src="figures/apple.gif" style="width:150px; height:150px; object-fit: cover;" alt="apple original"/></td>
      <td style="width: 100px;">5.52</td>
      <td style="width: 150px;"><img src="figures/apple_trt.gif" style="width:150px; height:150px; object-fit: cover;" alt="apple TRT"/></td>
      <td style="width: 100px;">0.75</td>
    </tr>
    <tr>
      <td style="width: 120px;">Multiview</td>
      <td style="width: 150px;"><img src="figures/airplane.png" style="width:150px; height:150px; object-fit: cover;" alt="airplane input"/></td>
      <td style="width: 150px;"><img src="figures/plane.gif" style="width:150px; height:150px; object-fit: cover;" alt="airplane original"/></td>
      <td style="width: 100px;">6.50</td>
      <td style="width: 150px;"><img src="figures/plane_trt.gif" style="width:150px; height:150px; object-fit: cover;" alt="airplane TRT"/></td>
      <td style="width: 100px;">1.1</td>
    </tr>
    <tr>
      <td style="width: 120px;">Pointcloud</td>
      <td style="width: 150px;"><img src="figures/ring.png" style="width:150px; height:150px; object-fit: cover;" alt="ring input"/></td>
      <td style="width: 150px;"><img src="figures/ring.gif" style="width:150px; height:150px; object-fit: cover;" alt="ring original"/></td>
      <td style="width: 100px;">9.3</td>
      <td style="width: 150px;"><img src="figures/ring_trt.gif" style="width:150px; height:150px; object-fit: cover;" alt="ring TRT"/></td>
      <td style="width: 100px;">1.2</td>
    </tr>
    <tr>
      <td style="width: 120px;">Voxels</td>
      <td style="width: 150px;"><img src="figures/horse.png" style="width:150px; height:150px; object-fit: cover;" alt="horse input"/></td>
      <td style="width: 150px;"><img src="figures/horse.gif" style="width:150px; height:150px; object-fit: cover;" alt="horse original"/></td>
      <td style="width: 100px;">9.5</td>
      <td style="width: 150px;"><img src="figures/horse_trt.gif" style="width:150px; height:150px; object-fit: cover;" alt="horse TRT"/></td>
      <td style="width: 100px;">0.6</td>
    </tr>
  </tbody>
</table>

## Installation

- Python >= 3.10
- CUDA (if available)
- PyTorch ([installation guide](https://pytorch.org/get-started/locally/))
- Other dependencies:  
  ```sh
  pip install -r requirements.txt
  ```

## Usage

### ONNX Export

Export the model to ONNX format for the desired modality using the command-line. For example, to export the pointcloud modality:

```sh
python Optim/ONNX_Export.py --modality pointcloud
```

Other modality examples:
```sh
python Optim/ONNX_Export.py --modality voxels
python Optim/ONNX_Export.py --modality sv
python Optim/ONNX_Export.py --modality sketch
python Optim/ONNX_Export.py --modality mv
```

### TensorRT Engine Conversion

Convert the exported ONNX model to a TensorRT engine. For example, to convert the pointcloud model:

```sh
python Optim/TRT_Conversion.py --onnx_path model_pointcloud.onnx --engine_path model_pointcloud.trt
```

Other examples:
```sh
python Optim/TRT_Conversion.py --onnx_path model_voxels.onnx --engine_path model_voxels.trt
python Optim/TRT_Conversion.py --onnx_path model_sv.onnx --engine_path model_sv.trt
python Optim/TRT_Conversion.py --onnx_path model_sketch.onnx --engine_path model_sketch.trt
python Optim/TRT_Conversion.py --onnx_path model_mv.onnx --engine_path model_mv.trt
```

### Running Inference with TensorRT

Run optimized inference using the TensorRT engine with argparse configuration. For example, to run inference on pointcloud data:

```sh
python Optim/TRT_Run.py --input_dir input_pointclouds --save_dir output_objs --engine_path model_pointcloud.trt --modality pointcloud
```

Additional examples:
```sh
# Single-view / Sketch
python Optim/TRT_Run.py --input_dir input_images --save_dir output_objs --engine_path model_singleview.trt --modality singleview

# Multiview
python Optim/TRT_Run.py --input_dir input_multiview --save_dir output_objs --engine_path model_multiview.trt --modality multiview

# Voxels
python Optim/TRT_Run.py --input_dir input_voxels --save_dir output_objs --engine_path model_voxels.trt --modality voxels
```

## Citation

```bibtex
@misc{sanghi2024waveletlatentdiffusionwala,
  title={Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings},
  author={Aditya Sanghi et al.},
  year={2024},
  eprint={2411.08017},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2411.08017}
}
```

## License

This project is licensed under the MIT License.